{{/*
=============================================================================
Grey Distributed â€” Worker Deployment
=============================================================================

Workers execute scheduled tasks. Deployment enables:
- Horizontal scaling via HPA
- Rolling updates with zero downtime
- Ephemeral instances (no persistent state)

=============================================================================
*/}}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "grey.fullname" . }}-worker
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "grey.worker.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.worker.replicas }}
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: {{ .Values.worker.maxUnavailable | default "25%" }}
      maxSurge: {{ .Values.worker.maxSurge | default "25%" }}
  selector:
    matchLabels:
      {{- include "grey.worker.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "grey.worker.labels" . | nindent 8 }}
        {{- with .Values.worker.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
      annotations:
        grey.io/config-checksum: {{ include "grey.configChecksum" . }}
        prometheus.io/scrape: "true"
        prometheus.io/port: {{ .Values.monitoring.prometheus.port | default "9090" | quote }}
        prometheus.io/path: "/metrics"
        {{- with .Values.worker.podAnnotations }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      serviceAccountName: {{ include "grey.worker.serviceAccountName" . }}
      terminationGracePeriodSeconds: {{ .Values.worker.terminationGracePeriodSeconds | default 30 }}
      
      {{- with .Values.global.image.pullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      
      {{- if .Values.worker.priorityClassName }}
      priorityClassName: {{ .Values.worker.priorityClassName }}
      {{- end }}
      
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
      
      # Anti-affinity: spread workers across nodes
      affinity:
        {{- if .Values.worker.affinity }}
        {{- toYaml .Values.worker.affinity | nindent 8 }}
        {{- else }}
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    {{- include "grey.worker.selectorLabels" . | nindent 20 }}
                topologyKey: kubernetes.io/hostname
        {{- end }}
      
      {{- with .Values.worker.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      
      {{- with .Values.worker.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      
      {{- with .Values.worker.topologySpreadConstraints }}
      topologySpreadConstraints:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      
      containers:
        - name: worker
          image: {{ include "grey.image" . }}
          imagePullPolicy: {{ .Values.global.image.pullPolicy }}
          
          command:
            - /usr/bin/grey-worker
          args:
            - --config=/etc/grey/config.yaml
            - --coordinator-service={{ include "grey.fullname" . }}-coordinator.{{ .Release.Namespace }}.svc.cluster.local
            - --grpc-port={{ .Values.worker.service.grpcPort }}
            {{- if .Values.security.mtls.enabled }}
            - --tls-cert=/etc/grey/certs/tls.crt
            - --tls-key=/etc/grey/certs/tls.key
            - --tls-ca=/etc/grey/certs/ca.crt
            {{- end }}
            {{- range .Values.worker.extraArgs }}
            - {{ . | quote }}
            {{- end }}
          
          env:
            {{- include "grey.commonEnv" . | nindent 12 }}
            - name: GREY_ROLE
              value: "worker"
            - name: GREY_CLUSTER_NAME
              value: {{ .Values.global.clusterName | default "grey-cluster" | quote }}
            # Worker pool identification for scheduling
            - name: GREY_WORKER_POOL
              value: {{ .Values.worker.pool | default "default" | quote }}
            {{- with .Values.worker.extraEnv }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          
          ports:
            - name: grpc
              containerPort: {{ .Values.worker.service.grpcPort }}
              protocol: TCP
            - name: metrics
              containerPort: {{ .Values.monitoring.prometheus.port | default 9090 }}
              protocol: TCP
          
          resources:
            {{- toYaml .Values.worker.resources | nindent 12 }}
          
          livenessProbe:
            {{- if .Values.worker.livenessProbe }}
            {{- toYaml .Values.worker.livenessProbe | nindent 12 }}
            {{- else }}
            grpc:
              port: {{ .Values.worker.service.grpcPort }}
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
            {{- end }}
          
          readinessProbe:
            {{- if .Values.worker.readinessProbe }}
            {{- toYaml .Values.worker.readinessProbe | nindent 12 }}
            {{- else }}
            grpc:
              port: {{ .Values.worker.service.grpcPort }}
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 3
            {{- end }}
          
          volumeMounts:
            {{- include "grey.commonVolumeMounts" . | nindent 12 }}
            # Ephemeral scratch space for task execution
            - name: scratch
              mountPath: /scratch
            {{- with .Values.worker.extraVolumeMounts }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop:
                - ALL
      
      volumes:
        {{- include "grey.commonVolumes" . | nindent 8 }}
        - name: scratch
          emptyDir:
            medium: {{ .Values.worker.scratchMedium | default "" | quote }}
            sizeLimit: {{ .Values.worker.scratchSizeLimit | default "5Gi" }}
        {{- with .Values.worker.extraVolumes }}
        {{- toYaml . | nindent 8 }}
        {{- end }}

---
# HorizontalPodAutoscaler for workers
{{- if .Values.worker.autoscaling.enabled }}
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: {{ include "grey.fullname" . }}-worker
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "grey.worker.labels" . | nindent 4 }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{ include "grey.fullname" . }}-worker
  minReplicas: {{ .Values.worker.autoscaling.minReplicas }}
  maxReplicas: {{ .Values.worker.autoscaling.maxReplicas }}
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: {{ .Values.worker.autoscaling.targetCPU }}
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: {{ .Values.worker.autoscaling.targetMemory }}
    {{- if .Values.worker.autoscaling.customMetrics }}
    {{- range .Values.worker.autoscaling.customMetrics }}
    - type: Pods
      pods:
        metric:
          name: {{ .name }}
        target:
          type: AverageValue
          averageValue: {{ .target }}
    {{- end }}
    {{- end }}
  behavior:
    scaleDown:
      stabilizationWindowSeconds: {{ .Values.worker.autoscaling.scaleDownStabilization | default 300 }}
      policies:
        - type: Percent
          value: 25
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: {{ .Values.worker.autoscaling.scaleUpStabilization | default 0 }}
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
        - type: Pods
          value: 4
          periodSeconds: 15
      selectPolicy: Max
{{- end }}

---
# PodDisruptionBudget for workers
{{- if .Values.worker.pdb.enabled }}
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: {{ include "grey.fullname" . }}-worker
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "grey.worker.labels" . | nindent 4 }}
spec:
  {{- if .Values.worker.pdb.minAvailable }}
  minAvailable: {{ .Values.worker.pdb.minAvailable }}
  {{- else }}
  maxUnavailable: {{ .Values.worker.pdb.maxUnavailable | default "25%" }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "grey.worker.selectorLabels" . | nindent 6 }}
{{- end }}

---
# ServiceAccount for worker pods
{{- if .Values.worker.serviceAccount.create }}
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ include "grey.worker.serviceAccountName" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "grey.worker.labels" . | nindent 4 }}
  {{- with .Values.worker.serviceAccount.annotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
automountServiceAccountToken: {{ .Values.worker.serviceAccount.automountServiceAccountToken | default true }}
{{- end }}
