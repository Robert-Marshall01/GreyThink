// ═══════════════════════════════════════════════════════════════════════════
// Grey++ AI / Machine Learning — Neural Networks & Inference
// Replaces: Python/PyTorch, TensorFlow, scikit-learn, Keras
// Demonstrates: Perceptron, Neural Net, Training Loop, Dataset, Evaluation
// ═══════════════════════════════════════════════════════════════════════════

section("GREY++ AI / MACHINE LEARNING")

// ── 1. Linear Algebra Primitives ────────────────────────────────────────────
section("1. Linear Algebra Primitives")

fn vec_add(a, b) { map(range(0, len(a)), fn(i) { get(a, i) + get(b, i) }) }
fn vec_sub(a, b) { map(range(0, len(a)), fn(i) { get(a, i) - get(b, i) }) }
fn vec_scale(v, s) { map(v, fn(x) { x * s }) }
fn dot(a, b) { reduce(range(0, len(a)), fn(acc, i) { acc + get(a, i) * get(b, i) }, 0) }
fn vec_norm(v) { sqrt(dot(v, v)) }
fn vec_normalize(v) { fn n() { vec_norm(v) } if_then(n() == 0, v, vec_scale(v, 1 / n())) }

fn demo_linalg() {
    fn a() { [1, 2, 3] }
    fn b() { [4, 5, 6] }

    print(str("  a = ", json_stringify(a())))
    print(str("  b = ", json_stringify(b())))
    print(str("  a + b = ", json_stringify(vec_add(a(), b()))))
    print(str("  a · b = ", dot(a(), b())))
    print(str("  |a| = ", round(vec_norm(a()) * 1000) / 1000))
    print(str("  3·a = ", json_stringify(vec_scale(a(), 3))))
}

demo_linalg()

// ── 2. Activation Functions ─────────────────────────────────────────────────
section("2. Activation Functions")

fn sigmoid(x) { 1 / (1 + exp(0 - x)) }
fn sigmoid_deriv(x) { fn s() { sigmoid(x) } s() * (1 - s()) }
fn relu(x) { max(0, x) }
fn relu_deriv(x) { if_then(x > 0, 1, 0) }
fn tanh_act(x) { fn ex() { exp(2 * x) } (ex() - 1) / (ex() + 1) }

fn demo_activations() {
    fn test_vals() { [0 - 2, 0 - 1, 0, 0.5, 1, 2] }
    forEach(test_vals(), fn(x) {
        print(str("  x=", pad_end(to_string(x), 5, " "),
            " sigmoid=", pad_end(to_string(round(sigmoid(x) * 1000) / 1000), 6, " "),
            " relu=", pad_end(to_string(relu(x)), 4, " "),
            " tanh=", round(tanh_act(x) * 1000) / 1000))
    })
}

demo_activations()

// ── 3. Single Perceptron — Trainable ────────────────────────────────────────
section("3. Trainable Perceptron (AND gate)")

fn Perceptron(weights, bias, learning_rate) {
    {
        weights: weights,
        bias: bias,
        predict: fn(inputs) {
            fn z() { dot(weights, inputs) + bias }
            if_then(z() >= 0.5, 1, 0)
        },
        predict_raw: fn(inputs) { sigmoid(dot(weights, inputs) + bias) },
        train_step: fn(inputs, target) {
            fn z() { dot(weights, inputs) + bias }
            fn output() { sigmoid(z()) }
            fn err() { target - output() }

            fn new_weights() {
                map(range(0, len(weights)), fn(i) {
                    get(weights, i) + learning_rate * err() * get(inputs, i)
                })
            }
            fn new_bias() { bias + learning_rate * err() }

            Perceptron(new_weights(), new_bias(), learning_rate)
        }
    }
}

fn demo_perceptron() {
    // AND truth table
    fn training_data() {
        [
            { inputs: [0, 0], target: 0 },
            { inputs: [0, 1], target: 0 },
            { inputs: [1, 0], target: 0 },
            { inputs: [1, 1], target: 1 }
        ]
    }

    // Initialize with small random weights
    fn initial() { Perceptron([0.1, 0.1], 0 - 0.2, 0.5) }

    // Train for multiple epochs
    fn train_epoch(perceptron, data, epoch) {
        fn result() {
            reduce(data, fn(p, sample) {
                get(p, "train_step")(get(sample, "inputs"), get(sample, "target"))
            }, perceptron)
        }
        result()
    }

    fn train_n_epochs(perceptron, data, n) {
        if_then(n <= 0,
            perceptron,
            fn() { train_n_epochs(train_epoch(perceptron, data, n), data, n - 1) }
        )
    }

    fn trained() { train_n_epochs(initial(), training_data(), 100) }

    print("  After 100 epochs:")
    forEach(training_data(), fn(sample) {
        fn inp() { get(sample, "inputs") }
        fn pred() { get(trained(), "predict")(inp()) }
        fn raw() { round(get(trained(), "predict_raw")(inp()) * 1000) / 1000 }
        print(str("    ", json_stringify(inp()), " → ", pred(), " (raw: ", raw(), ") expected: ", get(sample, "target")))
    })

    print(str("  Final weights: ", json_stringify(map(get(trained(), "weights"), fn(w) { round(w * 1000) / 1000 }))))
    print(str("  Final bias: ", round(get(trained(), "bias") * 1000) / 1000))
}

demo_perceptron()

// ── 4. Dataset & Preprocessing ──────────────────────────────────────────────
section("4. Dataset Operations")

fn Dataset(data, labels) {
    {
        data: data,
        labels: labels,
        size: fn() { len(data) },
        normalize: fn() {
            fn feature_count() { len(head(data)) }
            fn col(j) { map(data, fn(row) { get(row, j) }) }
            fn col_min(j) { reduce(col(j), fn(a, b) { min(a, b) }, get(head(data), j)) }
            fn col_max(j) { reduce(col(j), fn(a, b) { max(a, b) }, get(head(data), j)) }

            fn normalize_row(row) {
                map(range(0, feature_count()), fn(j) {
                    fn rng() { col_max(j) - col_min(j) }
                    if_then(rng() == 0, 0, (get(row, j) - col_min(j)) / rng())
                })
            }

            Dataset(map(data, fn(row) { normalize_row(row) }), labels)
        },
        split: fn(ratio) {
            fn split_idx() { floor(len(data) * ratio) }
            {
                train: Dataset(take(data, split_idx()), take(labels, split_idx())),
                test: Dataset(drop(data, split_idx()), drop(labels, split_idx()))
            }
        },
        describe: fn() {
            fn feature_count() { len(head(data)) }
            fn label_counts() { group_by(labels, fn(l) { l }) }
            {
                samples: len(data),
                features: feature_count(),
                class_distribution: map(entries(label_counts()), fn(e) { str(get(e, 0), ": ", len(get(e, 1))) })
            }
        }
    }
}

fn demo_dataset() {
    //  features: [height_cm, weight_kg, age]
    fn data() {
        [
            [170, 70, 30], [180, 85, 25], [160, 55, 40], [175, 78, 35],
            [165, 60, 28], [190, 95, 22], [155, 50, 45], [185, 88, 31],
            [172, 72, 38], [168, 65, 27]
        ]
    }
    fn labels() { [1, 1, 0, 1, 0, 1, 0, 1, 1, 0] }

    fn ds() { Dataset(data(), labels()) }
    fn ds_norm() { get(ds(), "normalize")() }
    fn splits() { get(ds_norm(), "split")(0.8) }

    print(str("  Dataset: ", json_stringify(get(ds(), "describe")())))
    print(str("  Train size: ", get(get(splits(), "train"), "size")()))
    print(str("  Test size: ", get(get(splits(), "test"), "size")()))
    print(str("  Normalized sample: ", json_stringify(head(get(ds_norm(), "data")))))
}

demo_dataset()

// ── 5. Model Evaluation Metrics ─────────────────────────────────────────────
section("5. Model Evaluation Metrics")

fn accuracy(predictions, actuals) {
    fn correct() { reduce(range(0, len(predictions)), fn(acc, i) { acc + if_then(get(predictions, i) == get(actuals, i), 1, 0) }, 0) }
    round(correct() / len(predictions) * 10000) / 100
}

fn precision(predictions, actuals, pos_label) {
    fn true_pos() { reduce(range(0, len(predictions)), fn(acc, i) { acc + if_then(and(get(predictions, i) == pos_label, get(actuals, i) == pos_label), 1, 0) }, 0) }
    fn pred_pos() { count(predictions, fn(p) { p == pos_label }) }
    if_then(pred_pos() == 0, 0, round(true_pos() / pred_pos() * 10000) / 100)
}

fn recall(predictions, actuals, pos_label) {
    fn true_pos() { reduce(range(0, len(predictions)), fn(acc, i) { acc + if_then(and(get(predictions, i) == pos_label, get(actuals, i) == pos_label), 1, 0) }, 0) }
    fn actual_pos() { count(actuals, fn(a) { a == pos_label }) }
    if_then(actual_pos() == 0, 0, round(true_pos() / actual_pos() * 10000) / 100)
}

fn f1_score(prec, rec) {
    if_then(prec + rec == 0, 0, round(2 * prec * rec / (prec + rec) * 100) / 100)
}

fn demo_metrics() {
    fn preds()   { [1, 1, 0, 1, 0, 1, 0, 0, 1, 1] }
    fn actuals() { [1, 0, 0, 1, 0, 1, 1, 0, 1, 0] }

    fn acc()  { accuracy(preds(), actuals()) }
    fn prec() { precision(preds(), actuals(), 1) }
    fn rec()  { recall(preds(), actuals(), 1) }
    fn f1()   { f1_score(prec(), rec()) }

    print(str("  Accuracy:  ", acc(), "%"))
    print(str("  Precision: ", prec(), "%"))
    print(str("  Recall:    ", rec(), "%"))
    print(str("  F1 Score:  ", f1()))
}

demo_metrics()

divider()
print("AI/ML demo complete — Linear algebra, Activations, Perceptron training, Dataset ops, Metrics all working.")
